"""
GitHub ì €ì¥ì†Œ ë¶„ì„ ë° ì„ë² ë”©ì„ ìœ„í•œ ëª¨ë“ˆ

ì´ ëª¨ë“ˆì€ GitHub ì €ì¥ì†Œì˜ ë‚´ìš©ì„ ê°€ì ¸ì™€ì„œ ë¶„ì„í•˜ê³ , 
LangChain Documentë¡œ ë³€í™˜í•œ í›„ ChromaDBì— ì„ë² ë”©í•˜ì—¬ ì €ì¥í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

ì£¼ìš” í´ë˜ìŠ¤:
    - GitHubRepositoryFetcher: GitHub ì €ì¥ì†Œì—ì„œ íŒŒì¼ì„ ê°€ì ¸ì˜¤ëŠ” í´ë˜ìŠ¤
    - RepositoryEmbedder: ì €ì¥ì†Œ ë‚´ìš©ì„ ì„ë² ë”©í•˜ëŠ” í´ë˜ìŠ¤

ì£¼ìš” í•¨ìˆ˜:
    - analyze_repository: GitHub ì €ì¥ì†Œë¥¼ ë¶„ì„í•˜ê³  ì„ë² ë”©í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
"""

import requests
import chromadb
import os
import re
import openai
import git
import base64
from typing import Optional, List, Dict, Any, Tuple
from langchain.schema import Document
from cryptography.fernet import Fernet
import tiktoken
import ast
import markdown
import concurrent.futures
import asyncio
import sys

# ----------------- ìƒìˆ˜ ì •ì˜ -----------------
MAIN_EXTENSIONS = ['.py', '.js', '.md']  # ë¶„ì„í•  ì£¼ìš” íŒŒì¼ í™•ì¥ì
CHUNK_SIZE = 500  # í…ìŠ¤íŠ¸ ì²­í¬ í¬ê¸°
GITHUB_TOKEN = "GITHUB_TOKEN"  # í™˜ê²½ ë³€ìˆ˜ í‚¤ ì´ë¦„
KEY_FILE = ".key"  # ì•”í˜¸í™” í‚¤ íŒŒì¼

# ChromaDB ê¸°ë³¸ í´ë¼ì´ì–¸íŠ¸ (ë¡œì»¬)
chroma_client = chromadb.Client()

def analyze_repository(repo_url: str, token: Optional[str] = None, session_id: Optional[str] = None) -> Dict[str, Any]:
    """
    GitHub ì €ì¥ì†Œë¥¼ ë¶„ì„í•˜ê³  ì„ë² ë”©í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜
    
    ì´ í•¨ìˆ˜ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ë‹¨ê³„ë¡œ ë™ì‘í•©ë‹ˆë‹¤:
    1. GitHub ì €ì¥ì†Œë¥¼ ë¡œì»¬ì— í´ë¡ 
    2. ì£¼ìš” íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì™€ì„œ í•„í„°ë§ (MAIN_EXTENSIONSì— ì •ì˜ëœ í™•ì¥ìë§Œ)
    3. íŒŒì¼ ë‚´ìš©ì„ ê°€ì ¸ì™€ì„œ ì„ë² ë”© ì²˜ë¦¬
    4. ë””ë ‰í† ë¦¬ êµ¬ì¡° íŠ¸ë¦¬ í…ìŠ¤íŠ¸ ìƒì„±
    
    Args:
        repo_url (str): ë¶„ì„í•  GitHub ì €ì¥ì†Œ URL
        token (Optional[str]): GitHub ê°œì¸ ì•¡ì„¸ìŠ¤ í† í°
        session_id (Optional[str]): ì„¸ì…˜ ID (ê¸°ë³¸ê°’: owner_repo)
        
    Returns:
        Dict[str, Any]:
            'files': ë¶„ì„ëœ íŒŒì¼ ëª©ë¡ (ê° íŒŒì¼ì€ {'path': '...', 'content': '...'} í˜•ì‹)
            'directory_structure': ë””ë ‰í† ë¦¬ êµ¬ì¡° íŠ¸ë¦¬ í…ìŠ¤íŠ¸
        
    Raises:
        ValueError: ì˜ëª»ëœ GitHub URLì¸ ê²½ìš°
        Exception: ì €ì¥ì†Œ í´ë¡  ì‹¤íŒ¨ ì‹œ
    """
    try:
        # 1. Git ì €ì¥ì†Œì—ì„œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        fetcher = GitHubRepositoryFetcher(repo_url, token, session_id)
        fetcher.clone_repo()
        
        # 2. ì£¼ìš” íŒŒì¼ í•„í„°ë§ ë° ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
        fetcher.filter_main_files()  # MAIN_EXTENSIONSì— ì •ì˜ëœ í™•ì¥ìë§Œ í•„í„°ë§
        files = fetcher.get_file_contents()

        # 3. ë°ì´í„° ì„ë² ë”© ì²˜ë¦¬
        embedder = RepositoryEmbedder(fetcher.session_id)
        embedder.process_and_embed(files)

        # 4. ë””ë ‰í† ë¦¬ êµ¬ì¡° íŠ¸ë¦¬ í…ìŠ¤íŠ¸ ìƒì„±
        directory_structure = fetcher.generate_directory_structure()
        
        return {
            'files': files,
            'directory_structure': directory_structure
        }
        
    except ValueError as e:
        print(f"[ì˜¤ë¥˜] ì˜ëª»ëœ GitHub URL: {e}")
        raise
    except Exception as e:
        print(f"[ì˜¤ë¥˜] ì €ì¥ì†Œ ë¶„ì„ ì‹¤íŒ¨: {e}")
        raise

class GitHubRepositoryFetcher:
    """
    GitHub ì €ì¥ì†Œì—ì„œ íŒŒì¼ì„ ê°€ì ¸ì˜¤ëŠ” í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ëŠ” GitHub APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì €ì¥ì†Œì˜ íŒŒì¼ê³¼ ë””ë ‰í† ë¦¬ë¥¼ ê°€ì ¸ì˜¤ê³ ,
    LangChain Document í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
    """
    
    def __init__(self, repo_url: str, token: Optional[str] = None, session_id: Optional[str] = None):
        """
        GitHub ì €ì¥ì†Œ ë·°ì–´ ì´ˆê¸°í™”
        
        Args:
            repo_url (str): GitHub ì €ì¥ì†Œ URL
            token (Optional[str]): GitHub ê°œì¸ ì•¡ì„¸ìŠ¤ í† í°
            session_id (Optional[str]): ì„¸ì…˜ ID (ê¸°ë³¸ê°’: owner_repo)
        """
        self.repo_url = repo_url
        self.token = token
        self.headers = {'Authorization': f'token {token}'} if token else {}
        self.files = []
        
        # ì €ì¥ì†Œ ì •ë³´ ì¶”ì¶œ
        self.owner, self.repo, self.path = self.extract_repo_info(repo_url)
        if not self.owner or not self.repo:
            raise ValueError("Invalid GitHub repository URL")
            
        # ì„¸ì…˜ ë° ì €ì¥ì†Œ ê²½ë¡œ ì„¤ì •
        self.session_id = session_id or f"{self.owner}_{self.repo}"
        self.repo_path = f"./repos/{self.session_id}"
        
        # ChromaDB ì»¬ë ‰ì…˜ ì´ˆê¸°í™”
        self.collection = chroma_client.get_or_create_collection(
            name=self.session_id,
            metadata={"description": f"Repository: {self.owner}/{self.repo}"}
        )

    def create_error_response(self, message: str, status_code: int) -> Dict[str, Any]:
        """
        API ì—ëŸ¬ ì‘ë‹µ ìƒì„±
        
        Args:
            message (str): ì—ëŸ¬ ë©”ì‹œì§€
            status_code (int): HTTP ìƒíƒœ ì½”ë“œ
            
        Returns:
            Dict[str, Any]: ì—ëŸ¬ ì •ë³´ë¥¼ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬
        """
        return {
            'error': True,
            'message': message,
            'status_code': status_code
        }

    def handle_github_response(self, response: requests.Response, path: str = None) -> Dict[str, Any]:
        """
        GitHub API ì‘ë‹µ ì²˜ë¦¬
        
        Args:
            response (requests.Response): GitHub API ì‘ë‹µ
            path (str, optional): ìš”ì²­í•œ íŒŒì¼/ë””ë ‰í† ë¦¬ ê²½ë¡œ
            
        Returns:
            Dict[str, Any]: ì²˜ë¦¬ëœ ì‘ë‹µ ë°ì´í„° ë˜ëŠ” ì—ëŸ¬ ì •ë³´
        """
        if response.status_code == 403:
            return self.create_error_response(
                'GitHub API í˜¸ì¶œ ì œí•œì— ë„ë‹¬í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.',
                403
            )
            
        if response.status_code == 404:
            return self.create_error_response(
                f'íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {path}' if path else 'ìš”ì²­í•œ ë¦¬ì†ŒìŠ¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
                404
            )
            
        if response.status_code == 401:
            return self.create_error_response(
                'ë¹„ê³µê°œ ì €ì¥ì†Œì— ì ‘ê·¼í•˜ë ¤ë©´ GitHub í† í°ì´ í•„ìš”í•©ë‹ˆë‹¤.',
                401
            )
            
        if response.status_code != 200:
            return self.create_error_response(
                f'GitHub API ì˜¤ë¥˜: {response.text}',
                response.status_code
            )
        
        return response.json()

    def extract_repo_info(self, url: str) -> Tuple[Optional[str], Optional[str], Optional[str]]:
        """
        GitHub URLì—ì„œ ì†Œìœ ì, ì €ì¥ì†Œ ì´ë¦„, íŒŒì¼ ê²½ë¡œë¥¼ ì¶”ì¶œ
        
        Args:
            url (str): GitHub ì €ì¥ì†Œ URL
            
        Returns:
            Tuple[Optional[str], Optional[str], Optional[str]]: 
                (owner, repo, path) ë˜ëŠ” (None, None, None)
        """
        try:
            # URL ì •ê·œí™”
            url = url.strip().rstrip('/')
            if url.endswith('.git'):
                url = url[:-4]
                
            # URL íŒŒì‹±
            parts = url.split('/')
            if 'github.com' in parts:
                github_index = parts.index('github.com')
                if len(parts) >= github_index + 3:
                    owner = parts[github_index + 1]
                    repo = parts[github_index + 2]
                    path = '/'.join(parts[github_index + 3:]) if len(parts) > github_index + 3 else None
                    return owner, repo, path
        except Exception as e:
            print(f"URL íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, None, None

    def clone_repo(self):
        """
        GitHub ì €ì¥ì†Œë¥¼ ë¡œì»¬ì— í´ë¡ 
        
        Raises:
            Exception: í´ë¡  ì‹¤íŒ¨ ì‹œ ì˜ˆì™¸ ë°œìƒ
        """
        if not os.path.exists(self.repo_path):
            try:
                git.Repo.clone_from(self.repo_url, self.repo_path)
            except Exception as e:
                print("[DEBUG] GitHub í´ë¡  ì—ëŸ¬:", e)
                raise

    def get_repo_directory_contents(self, path: str = "") -> Optional[List[Dict[str, Any]]]:
        """
        GitHub APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì €ì¥ì†Œì˜ ë””ë ‰í† ë¦¬ ë‚´ìš©ì„ ê°€ì ¸ì˜´
        
        Args:
            path (str): ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸ê°’: ë£¨íŠ¸ ë””ë ‰í† ë¦¬)
            
        Returns:
            Optional[List[Dict[str, Any]]]: 
                ë””ë ‰í† ë¦¬ ë‚´ìš© ëª©ë¡ ë˜ëŠ” ì—ëŸ¬ ì •ë³´
                ê° í•­ëª©ì€ GitHub API ì‘ë‹µ í˜•ì‹ì˜ íŒŒì¼/ë””ë ‰í† ë¦¬ ì •ë³´
        """
        try:
            # API í˜¸ì¶œ ì¤€ë¹„
            url = f"https://api.github.com/repos/{self.owner}/{self.repo}/contents/{path}"
            headers = {
                "Accept": "application/vnd.github.v3+json"
            }
            if self.token:
                headers["Authorization"] = f"token {self.token}"
            
            # API ìš”ì²­ ì‹¤í–‰
            response = requests.get(url, headers=headers)
            content = self.handle_github_response(response, path)
            
            # ì‘ë‹µ ê²€ì¦
            if isinstance(content, dict) and content.get('error'):
                return content
            if isinstance(content, list):
                return content
            return self.create_error_response("ì˜ëª»ëœ ì‘ë‹µ í˜•ì‹", 500)
            
        except requests.exceptions.RequestException as e:
            return self.create_error_response(f'API ìš”ì²­ ì‹¤íŒ¨: {str(e)}', 500)
        except Exception as e:
            return self.create_error_response(f'ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}', 500)
            
    def get_repo_content_as_document(self, path: str) -> Optional[Document]:
        """
        GitHub APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì €ì¥ì†Œì˜ íŒŒì¼ ë‚´ìš©ì„ LangChain Documentë¡œ ê°€ì ¸ì˜´
        
        Args:
            path (str): íŒŒì¼ ê²½ë¡œ
        
        Returns:
            Optional[Document]: 
                LangChain Document ê°ì²´ ë˜ëŠ” None (íŒŒì¼ì´ ì—†ëŠ” ê²½ìš°)
                DocumentëŠ” íŒŒì¼ ë‚´ìš©ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨
        """
        try:
            # API í˜¸ì¶œ ì¤€ë¹„
            url = f"https://api.github.com/repos/{self.owner}/{self.repo}/contents/{path}"
            headers = {
                "Accept": "application/vnd.github.v3+json"
            }
            if self.token:
                headers["Authorization"] = f"token {self.token}"
            
            # API ìš”ì²­ ì‹¤í–‰
            response = requests.get(url, headers=headers)
            content_data = self.handle_github_response(response, path)
            
            # ì—ëŸ¬ ì²´í¬
            if not content_data or isinstance(content_data, dict) and content_data.get('error'):
                return None
            
            # Base64 ë””ì½”ë”©
            content = base64.b64decode(content_data['content']).decode('utf-8')
            
            # Document ê°ì²´ ìƒì„±
            return Document(
                page_content=content,
                metadata={
                    'source': content_data['html_url'],
                    'file_name': content_data['name'],
                    'file_path': content_data['path'],
                    'sha': content_data['sha'],
                    'size': content_data['size'],
                    'type': content_data['type']
                }
            )
        except Exception as e:
            print(f"Document ë³€í™˜ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None

    def get_repo_directory_as_documents(self, path: str = "") -> List[Document]:
        """
        GitHub APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì €ì¥ì†Œì˜ ë””ë ‰í† ë¦¬ ë‚´ìš©ì„ LangChain Document ë¦¬ìŠ¤íŠ¸ë¡œ ê°€ì ¸ì˜´
        
        Args:
            path (str): ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸ê°’: ë£¨íŠ¸ ë””ë ‰í† ë¦¬)
            
        Returns:
            List[Document]: 
                LangChain Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
                ê° DocumentëŠ” íŒŒì¼ì˜ ë‚´ìš©ê³¼ ë©”íƒ€ë°ì´í„°ë¥¼ í¬í•¨
        """
        documents = []
        try:
            # ë””ë ‰í† ë¦¬ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
            dir_contents = self.get_repo_directory_contents(path)
            if not dir_contents:
                return documents
                
            # ê° í•­ëª© ì²˜ë¦¬
            for item in dir_contents:
                if item['type'] == 'file':
                    # íŒŒì¼ì¸ ê²½ìš° Documentë¡œ ë³€í™˜
                    doc = self.get_repo_content_as_document(item['path'])
                    if doc:
                        documents.append(doc)
                elif item['type'] == 'dir':
                    # ë””ë ‰í† ë¦¬ì¸ ê²½ìš° ì¬ê·€ì ìœ¼ë¡œ ì²˜ë¦¬
                    sub_docs = self.get_repo_directory_as_documents(item['path'])
                    documents.extend(sub_docs)
                    
            return documents
        except Exception as e:
            print(f"[API] Document ë¦¬ìŠ¤íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")
            return documents

    def get_all_repo_contents(self) -> List[Document]:
        """
        GitHub ì €ì¥ì†Œì˜ ëª¨ë“  íŒŒì¼ê³¼ í´ë”ë¥¼ LangChain Document ë¦¬ìŠ¤íŠ¸ë¡œ ê°€ì ¸ì˜´
        
        Returns:
            List[Document]: ëª¨ë“  íŒŒì¼ì˜ LangChain Document ê°ì²´ ë¦¬ìŠ¤íŠ¸
        """
        return self.get_repo_directory_as_documents()

    def get_all_main_files(self, path=""):
        files = []
        dir_contents = self.get_repo_directory_contents(path)
        if isinstance(dir_contents, list):
            for item in dir_contents:
                if item['type'] == 'file' and any(item['path'].endswith(ext) for ext in MAIN_EXTENSIONS):
                    files.append(item['path'])
                elif item['type'] == 'dir':
                    files.extend(self.get_all_main_files(item['path']))
        return files

    def filter_main_files(self):
        self.files = self.get_all_main_files()
        print(f"[DEBUG] í•„í„°ë§ëœ ì£¼ìš” íŒŒì¼: {self.files}")
        print(f"[DEBUG] ì£¼ìš” íŒŒì¼ ê°œìˆ˜: {len(self.files)}")

    def get_file_contents(self) -> List[Dict[str, Any]]:
        """
        ì£¼ìš” íŒŒì¼ì˜ ë‚´ìš©ì„ ì½ì–´ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜
        Returns:
            List[Dict[str, Any]]: 
                íŒŒì¼ ê²½ë¡œì™€ ë‚´ìš©ì„ í¬í•¨í•˜ëŠ” ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
                [{'path': '...', 'content': '...', 'file_name': ..., 'file_type': ..., 'sha': ..., 'source_url': ...}, ...]
        """
        file_objs = []
        for path in self.files:
            doc = self.get_repo_content_as_document(path)
            if doc:
                meta = doc.metadata
                file_objs.append({
                    'path': path,
                    'content': doc.page_content,
                    'file_name': meta.get('file_name'),
                    'file_type': meta.get('file_name', '').split('.')[-1] if meta.get('file_name') else '',
                    'sha': meta.get('sha'),
                    'source_url': meta.get('source'),
                })
        return file_objs

    def generate_directory_structure(self) -> str:
        """
        ì €ì¥ì†Œì˜ ì „ì²´ ë””ë ‰í† ë¦¬/íŒŒì¼ êµ¬ì¡°ë¥¼ íŠ¸ë¦¬ í˜•íƒœì˜ í…ìŠ¤íŠ¸ë¡œ ë°˜í™˜
        """
        # ë””ë ‰í† ë¦¬ ë‚´ìš© ì¬ê·€ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
        def build_tree(path=""):
            items = self.get_repo_directory_contents(path)
            tree = {}
            if not items or isinstance(items, dict) and items.get('error'):
                return tree
            for item in items:
                if item['type'] == 'file':
                    tree[f"ğŸ“„ {item['name']}"] = None
                elif item['type'] == 'dir':
                    tree[f"ğŸ“ {item['name']}"] = build_tree(item['path'])
            return tree
        
        tree = build_tree()
        lines = []
        def traverse(node, prefix=""):
            for key, value in sorted(node.items()):
                lines.append(f"{prefix}{key}")
                if value is not None:
                    traverse(value, prefix + "  ")
        traverse(tree)
        return "\n".join(lines)

    # ----------------- í† í° ê´€ë ¨ ê¸°ëŠ¥ -----------------
    @staticmethod
    def generate_key() -> bytes:
        """
        ì•”í˜¸í™” í‚¤ ìƒì„±
        
        Returns:
            bytes: ìƒì„±ëœ ì•”í˜¸í™” í‚¤
        """
        if not os.path.exists(KEY_FILE):
            key = Fernet.generate_key()
            with open(KEY_FILE, 'wb') as key_file:
                key_file.write(key)
            return key
        else:
            with open(KEY_FILE, 'rb') as key_file:
                return key_file.read()

    @staticmethod
    def encrypt_token(token: str) -> str:
        """
        í† í° ì•”í˜¸í™”
        
        Args:
            token (str): ì•”í˜¸í™”í•  í† í°
            
        Returns:
            str: ì•”í˜¸í™”ëœ í† í°
        """
        key = GitHubRepositoryFetcher.generate_key()
        f = Fernet(key)
        return f.encrypt(token.encode()).decode()

    @staticmethod
    def decrypt_token(encrypted_token: str) -> str:
        """
        í† í° ë³µí˜¸í™”
        
        Args:
            encrypted_token (str): ë³µí˜¸í™”í•  í† í°
            
        Returns:
            str: ë³µí˜¸í™”ëœ í† í°
        """
        key = GitHubRepositoryFetcher.generate_key()
        f = Fernet(key)
        return f.decrypt(encrypted_token.encode()).decode()

    @staticmethod
    def update_token(token: str) -> bool:
        """
        í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ì— GitHub í† í° ì—…ë°ì´íŠ¸
        
        Args:
            token (str): ì—…ë°ì´íŠ¸í•  í† í°
            
        Returns:
            bool: ì—…ë°ì´íŠ¸ ì„±ê³µ ì—¬ë¶€
        """
        try:
            # í† í° ì•”í˜¸í™”
            encrypted_token = GitHubRepositoryFetcher.encrypt_token(token)
            
            # ê¸°ì¡´ ë‚´ìš© ì½ê¸°
            with open(".env", 'r', encoding='utf-8') as f:
                lines = f.readlines()
            
            # GitHub í† í° ì°¾ì•„ì„œ êµì²´
            token_found = False
            for i, line in enumerate(lines):
                if line.startswith(f"{GITHUB_TOKEN}="):
                    lines[i] = f"{GITHUB_TOKEN}={encrypted_token}\n"
                    token_found = True
                    break
            
            # í† í°ì´ ì—†ìœ¼ë©´ ìƒˆë¡œ ì¶”ê°€
            if not token_found:
                lines.append(f"{GITHUB_TOKEN}={encrypted_token}\n")
            
            # íŒŒì¼ ë‹¤ì‹œ ì“°ê¸°
            with open(".env", 'w', encoding='utf-8') as f:
                f.writelines(lines)
            
            return True
        except Exception as e:
            print(f"[ì˜¤ë¥˜] í† í° ì €ì¥ ì‹¤íŒ¨: {str(e)}")
            return False


class RepositoryEmbedder:
    """
    ì €ì¥ì†Œ ë‚´ìš©ì„ ì„ë² ë”©í•˜ëŠ” í´ë˜ìŠ¤
    
    ì´ í´ë˜ìŠ¤ëŠ” GitHub ì €ì¥ì†Œì˜ íŒŒì¼ ë‚´ìš©ì„ ì²­í¬ë¡œ ë‚˜ëˆ„ê³ ,
    OpenAI APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ë² ë”©í•œ í›„ ChromaDBì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, session_id: str):
        """
        ì„ë² ë” ì´ˆê¸°í™”
        
        Args:
            session_id (str): ì„¸ì…˜ ID
        """
        self.session_id = session_id
        self.collection = chroma_client.get_or_create_collection(name=f"repo_{session_id}")

    def process_and_embed(self, files: List[Dict[str, Any]]):
        # ë‚´ë¶€ ë¹„ë™ê¸° í•¨ìˆ˜ ì •ì˜
        async def async_process_and_embed(files):
            import openai
            api_key = os.environ.get("OPENAI_API_KEY")
            client = openai.AsyncClient(api_key=api_key)
            enc = tiktoken.encoding_for_model("gpt-3.5-turbo")
            def safe_meta(meta):
                return {k: ('' if v is None else v if not isinstance(v, (int, float, bool)) else v) for k, v in meta.items()}
            def split_by_tokens(text, max_tokens=256, overlap=64):
                tokens = enc.encode(text)
                chunks = []
                start = 0
                while start < len(tokens):
                    end = min(start + max_tokens, len(tokens))
                    chunk = enc.decode(tokens[start:end])
                    chunks.append((chunk, start, end))
                    if end == len(tokens):
                        break
                    start += max_tokens - overlap
                return chunks
            def chunk_python_functions(source_code):
                try:
                    tree = ast.parse(source_code)
                except Exception:
                    return [(source_code, 0, len(enc.encode(source_code)), None, None, 1, len(source_code.splitlines()))]
                lines = source_code.splitlines()
                chunks = []
                for node in tree.body:
                    if isinstance(node, (ast.FunctionDef, ast.ClassDef)):
                        start = node.lineno - 1
                        end = getattr(node, 'end_lineno', None)
                        if end is None:
                            continue
                        chunk = '\n'.join(lines[start:end])
                        name = node.name
                        class_name = node.name if isinstance(node, ast.ClassDef) else None
                        func_name = node.name if isinstance(node, ast.FunctionDef) else None
                        if len(enc.encode(chunk)) > 256:
                            for sub_chunk, t_start, t_end in split_by_tokens(chunk, max_tokens=256, overlap=64):
                                chunks.append((sub_chunk, t_start, t_end, func_name, class_name, start+1, end))
                        else:
                            chunks.append((chunk, 0, len(enc.encode(chunk)), func_name, class_name, start+1, end))
                if not chunks:
                    for chunk, t_start, t_end in split_by_tokens(source_code, max_tokens=256, overlap=64):
                        chunks.append((chunk, t_start, t_end, None, None, 1, len(source_code.splitlines())))
                return chunks
            def chunk_markdown(md_text):
                pattern = r'(\n#+ .+|\n```[\s\S]+?```|\n\s*\n)'
                parts = re.split(pattern, md_text)
                chunks = []
                for part in parts:
                    part = part.strip()
                    if not part:
                        continue
                    if len(enc.encode(part)) > 256:
                        for chunk, t_start, t_end in split_by_tokens(part, max_tokens=256, overlap=64):
                            chunks.append((chunk, t_start, t_end, None, None, None, None))
                    else:
                        chunks.append((part, 0, len(enc.encode(part)), None, None, None, None))
                return chunks
            def chunk_js(source_code):
                return [(*x, None, None, None, None) for x in split_by_tokens(source_code, max_tokens=256, overlap=64)]
            # 1. ì „ì²´ ì²­í¬ ìˆ˜ì§‘
            all_chunks = []
            for file in files:
                content = file['content']
                path = file['path']
                ext = os.path.splitext(path)[1].lower()
                file_name = file.get('file_name')
                file_type = file.get('file_type')
                sha = file.get('sha')
                source_url = file.get('source_url')
                if ext == '.py':
                    chunks = chunk_python_functions(content)
                elif ext == '.md':
                    chunks = chunk_markdown(content)
                elif ext == '.js':
                    chunks = chunk_js(content)
                else:
                    chunks = [(*x, None, None, None, None) for x in split_by_tokens(content, max_tokens=256, overlap=64)]
                for i, (chunk, t_start, t_end, func_name, class_name, start_line, end_line) in enumerate(chunks):
                    all_chunks.append((chunk, file, i, t_start, t_end, func_name, class_name, start_line, end_line))
            # 2. ë¹„ë™ê¸° ì„ë² ë”©+ì—­í• íƒœê¹… í•¨ìˆ˜
            async def embed_and_tag_async(args, client):
                chunk, file, i, t_start, t_end, func_name, class_name, start_line, end_line = args
                # ì„ë² ë”©
                try:
                    emb_resp = await client.embeddings.create(
                        input=chunk,
                        model="text-embedding-3-small"
                    )
                    embedding = emb_resp.data[0].embedding
                except Exception as e:
                    print(f"[WARNING] ì„ë² ë”© ì‹¤íŒ¨: {e}")
                    embedding = [0.0] * 1536
                # ì—­í•  íƒœê¹…
                tag_prompt = f"ì•„ë˜ ì½”ë“œëŠ” ì–´ë–¤ ì—­í• (ê¸°ëŠ¥/ëª©ì )ì„ í•˜ë‚˜ìš”? í•œê¸€ë¡œ ê°„ë‹¨íˆ ìš”ì•½í•´ì¤˜.\n\nì½”ë“œ:\n{chunk}"
                try:
                    tag_resp = await client.chat.completions.create(
                        model="gpt-3.5-turbo",
                        messages=[{"role": "user", "content": tag_prompt}],
                        temperature=0.0,
                        max_tokens=32
                    )
                    role_tag = tag_resp.choices[0].message.content.strip()
                    print(f"[INFO] ì—­í•  íƒœê¹… ê²°ê³¼: íŒŒì¼={file.get('path')}, ì²­í¬={i}, ì—­í• ={role_tag}")
                except Exception as e:
                    print(f"[WARNING] ì—­í•  íƒœê¹… ì‹¤íŒ¨: {e}")
                    role_tag = ''
                return (embedding, role_tag, chunk, file, i, t_start, t_end, func_name, class_name, start_line, end_line)
            # 3. ë¹„ë™ê¸° ë³‘ë ¬ ì‹¤í–‰ (max_concurrent=20)
            print(f"[DEBUG] ì„ë² ë”©+ì—­í• íƒœê¹… asyncio ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ (ì²­í¬ ìˆ˜: {len(all_chunks)})")
            semaphore = asyncio.Semaphore(20)
            async def sem_task(args):
                async with semaphore:
                    return await embed_and_tag_async(args, client)
            tasks = [sem_task(args) for args in all_chunks]
            results = await asyncio.gather(*tasks)
            print(f"[DEBUG] ì„ë² ë”©+ì—­í• íƒœê¹… asyncio ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ")
            # 4. DB ì €ì¥ (ë™ê¸°)
            for embedding, role_tag, chunk, file, i, t_start, t_end, func_name, class_name, start_line, end_line in results:
                file_name = file.get('file_name')
                file_type = file.get('file_type')
                sha = file.get('sha')
                source_url = file.get('source_url')
                path = file['path']
                metadata = {
                    "path": path or '',
                    "file_name": file_name or '',
                    "file_type": file_type or '',
                    "sha": sha or '',
                    "source_url": source_url or '',
                    "chunk_index": i,
                    "function_name": func_name or '',
                    "class_name": class_name or '',
                    "start_line": start_line if start_line is not None else -1,
                    "end_line": end_line if end_line is not None else -1,
                    "token_start": t_start if t_start is not None else -1,
                    "token_end": t_end if t_end is not None else -1,
                    "role_tag": role_tag
                }
                self.collection.add(
                    ids=[f"{path}_{i}"],
                    embeddings=[embedding],
                    documents=[chunk],
                    metadatas=[safe_meta(metadata)]
                )
                print(f"[INFO] DB ì €ì¥: íŒŒì¼={path}, ì²­í¬={i}, ì—­í• ={role_tag}, ì„ë² ë”© ê¸¸ì´={len(embedding)}")
        # ë™ê¸° í•¨ìˆ˜ì—ì„œ ë¹„ë™ê¸° ì‹¤í–‰
        if sys.version_info >= (3, 7):
            asyncio.run(async_process_and_embed(files))
        else:
            raise RuntimeError("Python 3.7 ì´ìƒì—ì„œë§Œ ì§€ì›ë©ë‹ˆë‹¤.")