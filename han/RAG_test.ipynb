{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb3b22f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting cryptography\n",
      "  Downloading cryptography-45.0.3-cp37-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting cffi>=1.14 (from cryptography)\n",
      "  Downloading cffi-1.17.1-cp310-cp310-win_amd64.whl.metadata (1.6 kB)\n",
      "Collecting pycparser (from cffi>=1.14->cryptography)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Downloading cryptography-45.0.3-cp37-abi3-win_amd64.whl (3.4 MB)\n",
      "   ---------------------------------------- 0.0/3.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 3.4/3.4 MB 66.7 MB/s eta 0:00:00\n",
      "Downloading cffi-1.17.1-cp310-cp310-win_amd64.whl (181 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Installing collected packages: pycparser, cffi, cryptography\n",
      "\n",
      "   ------------- -------------------------- 1/3 [cffi]\n",
      "   -------------------------- ------------- 2/3 [cryptography]\n",
      "   ---------------------------------------- 3/3 [cryptography]\n",
      "\n",
      "Successfully installed cffi-1.17.1 cryptography-45.0.3 pycparser-2.22\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install cryptography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee5bed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì„¤ì¹˜] python-dotenv íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤...\n",
      "[ì„¤ì¹˜] python-dotenv íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ\n",
      "\n",
      "[í™˜ê²½] GitHub í† í°ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.\n",
      "GitHub í† í°: "
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\USER\\Desktop\\GitHub\\3rd_project\")  # chahae í´ë”ì˜ ìƒìœ„ í´ë”\n",
    "\n",
    "from chahae.github_repo_viewer import main\n",
    "\n",
    "\n",
    "documents = main(\"dfjoefjjdk\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36cc44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "def remove_db(db_name):    \n",
    "    # ì»¬ë ‰ì…˜ì„ ì§ì ‘ ì‚­ì œ\n",
    "    Chroma.delete_collection(name=\"your_collection_name\")\n",
    "\n",
    "def make_chroma_db(documents):\n",
    "    # Chunking\n",
    "    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "    docs = splitter.split_documents(documents)\n",
    "\n",
    "    # ë²¡í„° ì €ì¥ì†Œ ë§Œë“¤ê¸°\n",
    "    db = Chroma.from_documents(docs, OpenAIEmbeddings(), persist_directory=\"chroma_db\")\n",
    "    return db\n",
    "\n",
    "def get_top5_docs_from_db(query, db):\n",
    "    retriever = db.as_retriever(search_kwargs={\"k\": 5}) # ìƒìœ„ 5ê°œë§Œ ì¶”ì¶œí•˜ë„ë¡ ì„¤ì •\n",
    "\n",
    "    return retriever.get_relevant_documents(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e813c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "# OpenAI API í‚¤ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ì§ì ‘ ì…ë ¥)\n",
    "client = OpenAI()\n",
    "\n",
    "# ğŸ” GPTë¥¼ ì‚¬ìš©í•´ ìš”ì•½ ìƒì„±\n",
    "def summarize_with_gpt(content: str, file_path: str, max_chars: int = 1500) -> str:\n",
    "    prompt = f\"\"\"\n",
    "    ë‹¤ìŒì€ '{file_path}'ë¼ëŠ” íŒŒì¼ì˜ ì½”ë“œì…ë‹ˆë‹¤. \n",
    "    ì´ íŒŒì¼ì˜ ëª©ì ì´ ë¬´ì—‡ì¸ì§€, ì–´ë–¤ ê¸°ëŠ¥ì´ ìˆê³  ì–´ë–¤ ë¬¸ì œë¥¼ í•´ê²°í•˜ëŠ”ì§€ ê°„ë‹¨íˆ ìš”ì•½í•´ ì£¼ì„¸ìš”. \n",
    "    \\n\\n```python\\n{content[:max_chars]}\\n```\\n\\nìš”ì•½:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4.1\",  # ë˜ëŠ” gpt-3.5-turbo\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            temperature=0.3,\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ GPT ìš”ì•½ ì‹¤íŒ¨ ({file_path}): {e}\")\n",
    "        return \"ìš”ì•½ ì‹¤íŒ¨\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3rd_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
